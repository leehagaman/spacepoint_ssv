{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from particle import Particle # https://github.com/scikit-hep/particle\n",
    "\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reco BEE link: https://www.phy.bnl.gov/twister/bee/set/f51043f3-10d4-49b3-9866-bc7fbcf5d4fe/event/list/\n",
    "# truth BEE link: https://www.phy.bnl.gov/twister/bee/set/7ad1b4aa-a181-435a-9117-d37c0c9ca677/event/list/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76175fc0406f44a291f7fc00fedef6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading truth spacepoints from each event from the BEE link json (couldn't find this in the saved celltree.root output, maybe \"mc_trackPosition\", but I wasn't able to load it with uproot)\n",
    "\n",
    "truth_spacepoints = {}\n",
    "for dir in tqdm(os.listdir(\"input_files/misclustering_candidate_truth_outputs/bee/data/\")):\n",
    "    json_file = f\"input_files/misclustering_candidate_truth_outputs/bee/data/{dir}/{dir}-truthDepo.json\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        truth_data = json.load(f)\n",
    "    run = int(truth_data[\"runNo\"])\n",
    "    subrun = int(truth_data[\"subRunNo\"])\n",
    "    event = int(truth_data[\"eventNo\"])\n",
    "    curr_truth_spacepoints = np.column_stack((np.array(truth_data[\"x\"]) + 2, np.array(truth_data[\"y\"]), np.array(truth_data[\"z\"])))\n",
    "    truth_spacepoints[(run, subrun, event)] = curr_truth_spacepoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5247342308164fa29930b4f80bafcde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading reco spacepoints from each event\n",
    "\n",
    "reco_nu_spacepoints = {}\n",
    "reco_cosmic_spacepoints = {}\n",
    "reco_nu_vtxs = {}\n",
    "for file in tqdm(os.listdir(\"input_files/misclustering_candidate_nue_files\")):\n",
    "    if not file.endswith(\".root\"):\n",
    "        continue\n",
    "\n",
    "    f = uproot.open(f\"input_files/misclustering_candidate_nue_files/{file}\")\n",
    "\n",
    "    rse_df = f[\"Trun\"].arrays([\"runNo\", \"subRunNo\", \"eventNo\"], library=\"pd\")\n",
    "\n",
    "    run = int(rse_df[\"runNo\"].iloc[0])\n",
    "    subrun = int(rse_df[\"subRunNo\"].iloc[0])\n",
    "    event = int(rse_df[\"eventNo\"].iloc[0])\n",
    "\n",
    "    rse = (run, subrun, event)\n",
    "\n",
    "    curr_reco_nu_spacepoints_dic = f[\"T_rec_charge_blob\"].arrays([\"x\", \"y\", \"z\", \"q\"], library=\"np\")\n",
    "    curr_reco_nu_spacepoints = np.column_stack((curr_reco_nu_spacepoints_dic[\"x\"], curr_reco_nu_spacepoints_dic[\"y\"], curr_reco_nu_spacepoints_dic[\"z\"], curr_reco_nu_spacepoints_dic[\"q\"]))\n",
    "\n",
    "    curr_cosmic_spacepoints_dic = f[\"T_cluster\"].arrays([\"x\", \"y\", \"z\", \"q\"], library=\"np\")\n",
    "    curr_cosmic_spacepoints = np.column_stack((curr_cosmic_spacepoints_dic[\"x\"], curr_cosmic_spacepoints_dic[\"y\"], curr_cosmic_spacepoints_dic[\"z\"], curr_cosmic_spacepoints_dic[\"q\"]))\n",
    "\n",
    "    reco_nu_spacepoints[rse] = curr_reco_nu_spacepoints\n",
    "    reco_cosmic_spacepoints[rse] = curr_cosmic_spacepoints\n",
    "\n",
    "    reco_nu_vtx_dic = f[\"T_vtx\"].arrays([\"x\", \"y\", \"z\", \"flag_main\"], library=\"np\")\n",
    "    reco_nu_vtx_x = reco_nu_vtx_dic[\"x\"][reco_nu_vtx_dic[\"flag_main\"] == 1][0]\n",
    "    reco_nu_vtx_y = reco_nu_vtx_dic[\"y\"][reco_nu_vtx_dic[\"flag_main\"] == 1][0]\n",
    "    reco_nu_vtx_z = reco_nu_vtx_dic[\"z\"][reco_nu_vtx_dic[\"flag_main\"] == 1][0]\n",
    "\n",
    "    reco_nu_vtxs[rse] = (reco_nu_vtx_x, reco_nu_vtx_y, reco_nu_vtx_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsampling the cosmic spacepoints\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def fps_sampling(points, n_samples):\n",
    "    \"\"\"\n",
    "    Perform an optimized Farthest Point Sampling (FPS) using NumPy.\n",
    "\n",
    "    :param points: numpy array of shape (N, 3) representing the point cloud\n",
    "    :param n_samples: number of points to sample\n",
    "    :return: indices of sampled points\n",
    "    \"\"\"\n",
    "    N = points.shape[0]\n",
    "\n",
    "    if N == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    sampled_indices = np.zeros(n_samples, dtype=int)\n",
    "    distances = np.full(N, np.inf)\n",
    "\n",
    "    # Choose the first point randomly\n",
    "    sampled_indices[0] = np.random.randint(N)\n",
    "    \n",
    "    # Efficiently compute distances using vectorized operations\n",
    "    for i in range(1, n_samples):\n",
    "        # Update minimum distances\n",
    "        diff = points - points[sampled_indices[i - 1]]\n",
    "        new_distances = np.einsum('ij,ij->i', diff, diff)  # Faster squared Euclidean distance\n",
    "        distances = np.minimum(distances, new_distances)\n",
    "        \n",
    "        # Select the point farthest from the existing sampled set\n",
    "        sampled_indices[i] = np.argmax(distances)\n",
    "\n",
    "    sampled_points = points[sampled_indices]\n",
    "    \n",
    "    return sampled_points\n",
    "\n",
    "def fps_clustering_downsample(points, n_samples, debug=False):\n",
    "    \"\"\"\n",
    "    Downsample the point cloud using FPS and clustering.\n",
    "    \n",
    "    :param points: numpy array of shape (N, 3) representing the point cloud\n",
    "    :param n_samples: number of points in the downsampled cloud\n",
    "    :return: downsampled point cloud\n",
    "    \"\"\"\n",
    "\n",
    "    if debug:\n",
    "        print(f\"downsampling {points.shape[0]} points to {n_samples} points\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"performing FPS...\", end=\"\", flush=True)\n",
    "\n",
    "    # Perform FPS to get initial samples\n",
    "    sampled_points = fps_sampling(points, n_samples)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"done\", flush=True)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"performing KMeans...\", end=\"\", flush=True)\n",
    "\n",
    "    # Use K-means clustering to associate other points with the samples\n",
    "    kmeans = KMeans(n_clusters=n_samples, init=sampled_points, n_init=1)\n",
    "    kmeans.fit(points)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"done\", flush=True)\n",
    "        \n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "def get_min_dists(points_A, points_B):\n",
    "    \"\"\"\n",
    "    Get the minimum distance between each point in points_A and all the points in points_B.\n",
    "    \"\"\"\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(points_B)\n",
    "    distances, _ = nbrs.kneighbors(points_A)\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalculate_downsampling = False\n",
    "if recalculate_downsampling:\n",
    "    downsampled_cosmic_spacepoints = {}\n",
    "    for rse in tqdm(reco_cosmic_spacepoints.keys()):\n",
    "        downsampled_cosmic_spacepoints[rse] = fps_clustering_downsample(reco_cosmic_spacepoints[rse][:, :3], 1000)\n",
    "    with open(\"input_files/misclustering_candidate_nue_files/downsampled_cosmic_spacepoints.pkl\", \"wb\") as f:\n",
    "        pickle.dump(downsampled_cosmic_spacepoints, f)\n",
    "else:\n",
    "    with open(\"input_files/misclustering_candidate_nue_files/downsampled_cosmic_spacepoints.pkl\", \"rb\") as f:\n",
    "        downsampled_cosmic_spacepoints = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a51937df1d437280df8d206312db52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13779, 223, 11160) spacepoint counts:\n",
      "num cosmic spacepoints: 131889\n",
      "num downsampled cosmic spacepoints: 1000\n",
      "num truth spacepoints: 8338\n",
      "num reco neutrino spacepoints: 266\n",
      "num nearby reco cosmic downsampled cosmic spacepoints: 146\n",
      "num nearby cosmic downsampled spacepoints: 189\n"
     ]
    }
   ],
   "source": [
    "# splitting based on distances to things\n",
    "\n",
    "real_nu_reco_nu_downsampled_spacepoints = {}\n",
    "real_nu_reco_cosmic_downsampled_spacepoints = {}\n",
    "real_cosmic_reco_nu_downsampled_spacepoints = {}\n",
    "real_cosmic_reco_cosmic_downsampled_spacepoints = {}\n",
    "real_cosmic_reco_nu_downsampled_spacepoints = {}\n",
    "far_from_vtx_downsampled_spacepoints = {}\n",
    "\n",
    "for rse in tqdm(downsampled_cosmic_spacepoints.keys()):\n",
    "\n",
    "    min_cosmic_truth_dists = get_min_dists(downsampled_cosmic_spacepoints[rse][:, :3], truth_spacepoints[rse][:, :3])\n",
    "    min_cosmic_reco_nu_dists = get_min_dists(downsampled_cosmic_spacepoints[rse][:, :3], reco_nu_spacepoints[rse][:, :3])\n",
    "    cosmic_vtx_dists = np.sqrt((downsampled_cosmic_spacepoints[rse][:, 0] - reco_nu_vtxs[rse][0])**2\n",
    "                                + (downsampled_cosmic_spacepoints[rse][:, 1] - reco_nu_vtxs[rse][1])**2\n",
    "                                  + (downsampled_cosmic_spacepoints[rse][:, 2] - reco_nu_vtxs[rse][2])**2)\n",
    "\n",
    "    not_far_from_vtx_indices = np.where(cosmic_vtx_dists < 200.0)[0]\n",
    "    far_from_vtx_indices = np.where(cosmic_vtx_dists >= 200.0)[0]\n",
    "\n",
    "    close_to_truth_indices = np.where(min_cosmic_truth_dists < 5.0)[0]\n",
    "    far_from_truth_indices = np.where(min_cosmic_truth_dists >= 5.0)[0]\n",
    "\n",
    "    close_to_reco_nu_indices = np.where(min_cosmic_reco_nu_dists < 5.0)[0]\n",
    "    far_from_reco_nu_indices = np.where(min_cosmic_reco_nu_dists >= 5.0)[0]\n",
    "\n",
    "\n",
    "    real_nu_reco_nu_indices = np.intersect1d(close_to_reco_nu_indices, close_to_truth_indices)\n",
    "    real_nu_reco_cosmic_indices = np.intersect1d(far_from_reco_nu_indices, close_to_truth_indices)\n",
    "    real_cosmic_reco_nu_indices = np.intersect1d(close_to_reco_nu_indices, far_from_truth_indices)\n",
    "    real_cosmic_reco_cosmic_indices = np.intersect1d(far_from_reco_nu_indices, far_from_truth_indices)\n",
    "\n",
    "    real_nu_reco_nu_indices = np.intersect1d(real_nu_reco_nu_indices, not_far_from_vtx_indices)\n",
    "    real_nu_reco_cosmic_indices = np.intersect1d(real_nu_reco_cosmic_indices, not_far_from_vtx_indices)\n",
    "    real_cosmic_reco_nu_indices = np.intersect1d(real_cosmic_reco_nu_indices, not_far_from_vtx_indices)\n",
    "    real_cosmic_reco_cosmic_indices = np.intersect1d(real_cosmic_reco_cosmic_indices, not_far_from_vtx_indices)\n",
    "\n",
    "    missing_nu_indices = np.intersect1d(close_to_truth_indices, far_from_reco_nu_indices)\n",
    "    missing_nu_indices = np.intersect1d(missing_nu_indices, not_far_from_vtx_indices)\n",
    "    cosmic_indices = np.intersect1d(far_from_truth_indices, far_from_reco_nu_indices)\n",
    "    cosmic_indices = np.intersect1d(cosmic_indices, not_far_from_vtx_indices)\n",
    "    nu_indices = close_to_reco_nu_indices\n",
    "    nu_indices = np.intersect1d(close_to_reco_nu_indices, not_far_from_vtx_indices)\n",
    "\n",
    "    real_nu_reco_cosmic_downsampled_spacepoints[rse] = downsampled_cosmic_spacepoints[rse][real_nu_reco_cosmic_indices, :]\n",
    "    real_nu_reco_nu_downsampled_spacepoints[rse] = downsampled_cosmic_spacepoints[rse][real_nu_reco_nu_indices, :]\n",
    "    real_cosmic_reco_nu_downsampled_spacepoints[rse] = downsampled_cosmic_spacepoints[rse][real_cosmic_reco_nu_indices, :]\n",
    "    real_cosmic_reco_cosmic_downsampled_spacepoints[rse] = downsampled_cosmic_spacepoints[rse][real_cosmic_reco_cosmic_indices, :]\n",
    "    far_from_vtx_downsampled_spacepoints[rse] = downsampled_cosmic_spacepoints[rse][far_from_vtx_indices, :]\n",
    "\n",
    "    if rse == (13779, 223, 11160):\n",
    "        print(f\"{rse} spacepoint counts:\")\n",
    "        print(f\"num cosmic spacepoints: {len(reco_cosmic_spacepoints[rse])}\")\n",
    "        print(f\"num downsampled cosmic spacepoints: {len(downsampled_cosmic_spacepoints[rse])}\")\n",
    "        print(f\"num truth spacepoints: {len(truth_spacepoints[rse])}\")\n",
    "        print(f\"num reco neutrino spacepoints: {len(reco_nu_spacepoints[rse])}\")\n",
    "        print(f\"num nearby reco cosmic downsampled cosmic spacepoints: {len(real_nu_reco_cosmic_downsampled_spacepoints[rse]) + len(real_cosmic_reco_cosmic_downsampled_spacepoints[rse])}\")\n",
    "        print(f\"num nearby cosmic downsampled spacepoints: {len(not_far_from_vtx_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.165336\n",
      "0.200112\n",
      "0.006384\n"
     ]
    }
   ],
   "source": [
    "print(8*3*1_000_000*131_889/1e12)\n",
    "print(8*3*1_000_000*8_338/1e12)\n",
    "print(8*3*1_000_000*266/1e12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making detector boundary points\n",
    "\n",
    "tpc_min_x = -1.\n",
    "tpc_max_x = 254.3\n",
    "tpc_min_y = -115.\n",
    "tpc_max_y = 117.\n",
    "tpc_min_z = 0.6\n",
    "tpc_max_z = 1036.4\n",
    "\n",
    "def generate_box_edge_points(x_min, x_max, y_min, y_max, z_min, z_max, num_points_per_edge=10):\n",
    "\n",
    "    # Generate points along edges parallel to X-axis\n",
    "    t = np.linspace(0, 1, num_points_per_edge)\n",
    "    x_edges = [\n",
    "        np.column_stack([\n",
    "            x_min + t * (x_max - x_min),\n",
    "            np.full_like(t, y_min),\n",
    "            np.full_like(t, z_min)\n",
    "        ]),\n",
    "        np.column_stack([\n",
    "            x_min + t * (x_max - x_min),\n",
    "            np.full_like(t, y_max),\n",
    "            np.full_like(t, z_min)\n",
    "        ]),\n",
    "        np.column_stack([\n",
    "            x_min + t * (x_max - x_min),\n",
    "            np.full_like(t, y_min),\n",
    "            np.full_like(t, z_max)\n",
    "        ]),\n",
    "        np.column_stack([\n",
    "            x_min + t * (x_max - x_min),\n",
    "            np.full_like(t, y_max),\n",
    "            np.full_like(t, z_max)\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    # Generate points along edges parallel to Y-axis\n",
    "    y_edges = [\n",
    "        np.column_stack([\n",
    "            np.full_like(t, x_min),\n",
    "            y_min + t * (y_max - y_min),\n",
    "            np.full_like(t, z_min)\n",
    "        ]),\n",
    "        np.column_stack([\n",
    "            np.full_like(t, x_max),\n",
    "            y_min + t * (y_max - y_min),\n",
    "            np.full_like(t, z_min)\n",
    "        ]),\n",
    "        np.column_stack([\n",
    "            np.full_like(t, x_min),\n",
    "            y_min + t * (y_max - y_min),\n",
    "            np.full_like(t, z_max)\n",
    "        ]),\n",
    "        np.column_stack([\n",
    "            np.full_like(t, x_max),\n",
    "            y_min + t * (y_max - y_min),\n",
    "            np.full_like(t, z_max)\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    # Generate points along edges parallel to Z-axis\n",
    "    z_edges = [\n",
    "        np.column_stack([\n",
    "            np.full_like(t, x_min),\n",
    "            np.full_like(t, y_min),\n",
    "            z_min + t * (z_max - z_min)\n",
    "        ]),\n",
    "        np.column_stack([\n",
    "            np.full_like(t, x_max),\n",
    "            np.full_like(t, y_min),\n",
    "            z_min + t * (z_max - z_min)\n",
    "        ]),\n",
    "        np.column_stack([\n",
    "            np.full_like(t, x_min),\n",
    "            np.full_like(t, y_max),\n",
    "            z_min + t * (z_max - z_min)\n",
    "        ]),\n",
    "        np.column_stack([\n",
    "            np.full_like(t, x_max),\n",
    "            np.full_like(t, y_max),\n",
    "            z_min + t * (z_max - z_min)\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    # Combine all edges\n",
    "    all_points = np.vstack(x_edges + y_edges + z_edges)\n",
    "    return all_points\n",
    "\n",
    "\n",
    "detector_boundary_points = generate_box_edge_points(tpc_min_x, tpc_max_x, tpc_min_y, tpc_max_y, tpc_min_z, tpc_max_z, num_points_per_edge=100)\n",
    "x_width = tpc_max_x - tpc_min_x\n",
    "expanded_detector_boundary_points = generate_box_edge_points(tpc_min_x - x_width, tpc_max_x + x_width, tpc_min_y, tpc_max_y, tpc_min_z, tpc_max_z, num_points_per_edge=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rse_list = list(reco_nu_spacepoints.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rse: (13779, 223, 11160)\n"
     ]
    }
   ],
   "source": [
    "index = 50\n",
    "\n",
    "# 10 is good\n",
    "# 50 is perfect\n",
    "# 51 is good\n",
    "# 54 is good\n",
    "# 55 is okay\n",
    "# 57 is good, with a true cosmic reco nu track\n",
    "\n",
    "rse = rse_list[index]\n",
    "\n",
    "print(\"rse:\", rse)\n",
    "\n",
    "curr_detector_boundary_points = detector_boundary_points\n",
    "curr_expanded_detector_boundary_points = expanded_detector_boundary_points\n",
    "\n",
    "curr_reco_nu_spacepoints = reco_nu_spacepoints[rse]\n",
    "curr_truth_spacepoints = truth_spacepoints[rse]\n",
    "\n",
    "curr_far_from_vtx_downsampled_spacepoints = far_from_vtx_downsampled_spacepoints[rse]\n",
    "\n",
    "curr_real_nu_reco_cosmic_downsampled_spacepoints = real_nu_reco_cosmic_downsampled_spacepoints[rse]\n",
    "curr_real_nu_reco_nu_downsampled_spacepoints = real_nu_reco_nu_downsampled_spacepoints[rse]\n",
    "curr_real_cosmic_reco_nu_downsampled_spacepoints = real_cosmic_reco_nu_downsampled_spacepoints[rse]\n",
    "curr_real_cosmic_reco_cosmic_downsampled_spacepoints = real_cosmic_reco_cosmic_downsampled_spacepoints[rse]\n",
    "\n",
    "curr_downsampled_cosmic_spacepoints = downsampled_cosmic_spacepoints[rse]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=curr_expanded_detector_boundary_points[:, 2],\n",
    "    y=curr_expanded_detector_boundary_points[:, 0],\n",
    "    z=curr_expanded_detector_boundary_points[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=0.2,\n",
    "        color='black',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Expanded TPC Boundary'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=curr_detector_boundary_points[:, 2],\n",
    "    y=curr_detector_boundary_points[:, 0],\n",
    "    z=curr_detector_boundary_points[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        color='black',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='TPC Boundary'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[reco_nu_vtxs[rse][2]],\n",
    "    y=[reco_nu_vtxs[rse][0]],\n",
    "    z=[reco_nu_vtxs[rse][1]],\n",
    "    mode='markers',\n",
    "    marker=dict(size=10, color='orange', opacity=1),\n",
    "    name='Reco Neutrino Vertex'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=curr_real_cosmic_reco_cosmic_downsampled_spacepoints[:, 2],\n",
    "    y=curr_real_cosmic_reco_cosmic_downsampled_spacepoints[:, 0],\n",
    "    z=curr_real_cosmic_reco_cosmic_downsampled_spacepoints[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color='blue',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Correctly Identified Cosmic Downsampled Spacepoints'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=curr_real_nu_reco_nu_downsampled_spacepoints[:, 2],\n",
    "    y=curr_real_nu_reco_nu_downsampled_spacepoints[:, 0],\n",
    "    z=curr_real_nu_reco_nu_downsampled_spacepoints[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color='green',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Found Neutrino Downsampled Spacepoints'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=curr_real_nu_reco_cosmic_downsampled_spacepoints[:, 2],\n",
    "    y=curr_real_nu_reco_cosmic_downsampled_spacepoints[:, 0],\n",
    "    z=curr_real_nu_reco_cosmic_downsampled_spacepoints[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color='red',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Misidentified Neutrino Downsampled Spacepoints'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=curr_real_cosmic_reco_nu_downsampled_spacepoints[:, 2],\n",
    "    y=curr_real_cosmic_reco_nu_downsampled_spacepoints[:, 0],\n",
    "    z=curr_real_cosmic_reco_nu_downsampled_spacepoints[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color='brown',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Misidentified Cosmic Downsampled Spacepoints'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=np.append(curr_real_nu_reco_cosmic_downsampled_spacepoints[:, 2], curr_real_cosmic_reco_cosmic_downsampled_spacepoints[:, 2]),\n",
    "    y=np.append(curr_real_nu_reco_cosmic_downsampled_spacepoints[:, 0], curr_real_cosmic_reco_cosmic_downsampled_spacepoints[:, 0]),\n",
    "    z=np.append(curr_real_nu_reco_cosmic_downsampled_spacepoints[:, 1], curr_real_cosmic_reco_cosmic_downsampled_spacepoints[:, 1]),\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color='black',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='All Reconstructed Cosmic Downsampled Spacepoints'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=curr_downsampled_cosmic_spacepoints[:, 2],\n",
    "    y=curr_downsampled_cosmic_spacepoints[:, 0],\n",
    "    z=curr_downsampled_cosmic_spacepoints[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color='black',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='All Cosmic Downsampled Spacepoints'\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=curr_reco_nu_spacepoints[:, 2],\n",
    "    y=curr_reco_nu_spacepoints[:, 0],\n",
    "    z=curr_reco_nu_spacepoints[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color=curr_reco_nu_spacepoints[:, 3],\n",
    "        colorscale='Jet',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Neutrino Cluster Trajectory Spacepoints',\n",
    "    visible='legendonly'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=curr_truth_spacepoints[:, 2],\n",
    "    y=curr_truth_spacepoints[:, 0],\n",
    "    z=curr_truth_spacepoints[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color='orange', opacity=0.8),\n",
    "    name='BEE Truth Spacepoints',\n",
    "    visible='legendonly'\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='z',\n",
    "        yaxis_title='x',\n",
    "        zaxis_title='y',\n",
    "        aspectratio=dict(\n",
    "            x=5,\n",
    "            y=3,\n",
    "            z=1\n",
    "        ),\n",
    "    ),\n",
    "    width=2000,\n",
    "    height=1200,\n",
    "    autosize=False,\n",
    "    scene_camera=dict(\n",
    "        eye=dict(x=-1.5, y=-1.5, z=1.5)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show(renderer=\"browser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
